{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q tensorflow_io\n",
    "%pip install -U -q tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join, splitext\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_hub as tfhub\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "SEED = 1337\n",
    "MODEL_NAME = \"english_accent_recognition\"\n",
    "AUDIOPATH = os.getcwd() + '/data/audio'\n",
    "\n",
    "class_names = [\n",
    "    \"afrikaans\",\n",
    "    \"agni\",\n",
    "    \"akan\",\n",
    "    \"albanian\",\n",
    "    \"amharic\",\n",
    "    \"arabic\",\n",
    "    \"armenian\",\n",
    "    \"azerbaijani\",\n",
    "    \"belarusan\",\n",
    "    \"bafang\",\n",
    "    \"baga\",\n",
    "    \"bai\",\n",
    "    \"bambara\",\n",
    "    \"bamun\",\n",
    "    \"bavarian\",\n",
    "    \"burmese\",\n",
    "    \"balanta ganja\",\n",
    "    \"bari\",\n",
    "    \"basque\",\n",
    "    \"bengali\",\n",
    "    \"bosnian\",\n",
    "    \"bulgarian\",\n",
    "    \"chittagonian\",\n",
    "    \"croatian\",\n",
    "    \"cebuano\",\n",
    "    \"charapa-spanish\",\n",
    "    \"cantonese\",\n",
    "    \"chaldean\",\n",
    "    \"carolinian\",\n",
    "    \"catalan\",\n",
    "    \"chamorro\",\n",
    "    \"czech\",\n",
    "    \"dinka\",\n",
    "    \"danish\",\n",
    "    \"dari\",\n",
    "    \"dutch\",\n",
    "    \"ebira\",\n",
    "    \"edo\",\n",
    "    \"english\",\n",
    "    \"ewe\",\n",
    "    \"fang\",\n",
    "    \"faroese\",\n",
    "    \"fanti\",\n",
    "    \"farsi\",\n",
    "    \"filipino\",\n",
    "    \"finnish\",\n",
    "    \"french\",\n",
    "    \"frisian\",\n",
    "    \"gaddang\",\n",
    "    \"ga\",\n",
    "    \"gedeo\",\n",
    "    \"ganda\",\n",
    "    \"georgian\",\n",
    "    \"german\",\n",
    "    \"greek\",\n",
    "    \"gujarati\",\n",
    "    \"gusii\",\n",
    "    \"hebrew\",\n",
    "    \"hindi\",\n",
    "    \"haitian creole french\",\n",
    "    \"icelandic\",\n",
    "    \"xiang\",\n",
    "    \"hungarian\",\n",
    "    \"igbo\",\n",
    "    \"ibibio\",\n",
    "    \"indonesian\",\n",
    "    \"italian\",\n",
    "    \"japanese\",\n",
    "    \"javanese\",\n",
    "    \"kannada\",\n",
    "    \"kazakh\",\n",
    "    \"khmer\",\n",
    "    \"kyrgyz\",\n",
    "    \"kiswahili\",\n",
    "    \"korean\",\n",
    "    \"krio\",\n",
    "    \"kurdish\",\n",
    "    \"kalanga\",\n",
    "    \"kabyle\",\n",
    "    \"lingala\",\n",
    "    \"lamaholot\",\n",
    "    \"lao\",\n",
    "    \"latvian\",\n",
    "    \"lithuanian\",\n",
    "    \"luo\",\n",
    "    \"lamotrekese\",\n",
    "    \"macedonian\",\n",
    "    \"malay\",\n",
    "    \"malayalam\",\n",
    "    \"mandinka\",\n",
    "    \"mankanya\",\n",
    "    \"mandarin\",\n",
    "    \"mandingo\",\n",
    "    \"marathi\",\n",
    "    \"mauritian\",\n",
    "    \"mongolian\",\n",
    "    \"moore\",\n",
    "    \"mortlockese\",\n",
    "    \"nepali\",\n",
    "    \"nama\",\n",
    "    \"nandi\",\n",
    "    \"northern sotho\",\n",
    "    \"norwegian\",\n",
    "    \"oromo\",\n",
    "    \"pohnpeian\",\n",
    "    \"polish\",\n",
    "    \"portuguese\",\n",
    "    \"punjabi\",\n",
    "    \"pahari\",\n",
    "    \"quechua\",\n",
    "    \"romanian\",\n",
    "    \"russian\",\n",
    "    \"sardinian\",\n",
    "    \"sarua\",\n",
    "    \"sa&#39;a\",\n",
    "    \"satawalese\",\n",
    "    \"sindhi\",\n",
    "    \"serbian\",\n",
    "    \"swiss german\",\n",
    "    \"sicilian\",\n",
    "    \"sinhala\",\n",
    "    \"slovak\",\n",
    "    \"somali\",\n",
    "    \"sundanese\",\n",
    "    \"spanish\",\n",
    "    \"swedish\",\n",
    "    \"synthesized\",\n",
    "    \"tagalog\",\n",
    "    \"taishan\",\n",
    "    \"taiwanese\",\n",
    "    \"tamil\",\n",
    "    \"tatar\",\n",
    "    \"telugu\",\n",
    "    \"thai\",\n",
    "    \"tibetan\",\n",
    "    \"tigrigna\",\n",
    "    \"tok pisin\",\n",
    "    \"turkish\",\n",
    "    \"twi\",\n",
    "    \"urdu\",\n",
    "    \"uyghur\",\n",
    "    \"uzbek\",\n",
    "    \"vietnamese\",\n",
    "    \"wolof\",\n",
    "    \"yiddish\",\n",
    "    \"zulu\",\n",
    "    \"maltese\",\n",
    "    \"yoruba\",\n",
    "    \"yapese\",\n",
    "    \"mende\",\n",
    "    \"konkani\",\n",
    "    \"kikongo\",\n",
    "    \"kikuyu\",\n",
    "    \"oriya\",\n",
    "    \"tswana\",\n",
    "    \"teochew\",\n",
    "    \"yupik\",\n",
    "    \"ngemba\",\n",
    "    \"hindko\",\n",
    "    \"estonian\",\n",
    "    \"shona\",\n",
    "    \"amazigh\",\n",
    "    \"slovenian\",\n",
    "    \"ukrainian\",\n",
    "    \"fijian\",\n",
    "    \"rotuman\",\n",
    "    \"pashto\",\n",
    "    \"sesotho\",\n",
    "    \"newari\",\n",
    "    \"sylheti\",    \n",
    "    \"pulaar\",\n",
    "    \"serer\",\n",
    "    \"jola\",\n",
    "    \"xasonga\",\n",
    "    \"vlaams\",\n",
    "    \"hainanese\",\n",
    "    \"jamaican creole english\",\n",
    "    \"kambaata\",    \n",
    "    \"moba\",\n",
    "    \"fataluku\",\n",
    "    \"tetun-dili\",\n",
    "    \"susu\",\n",
    "    \"chichewa\",\n",
    "    \"hadiyya\",\n",
    "    \"shilluk\",    \n",
    "    \"hausa\",\n",
    "    \"fulfulde adamawa\",\n",
    "    \"rwanda\",\n",
    "    \"kanuri\",\n",
    "    \"yakut\",\n",
    "    \"rundi\",\n",
    "    \"luxembourgeois\",\n",
    "    \"malagasy\",\n",
    "    \"nuer\",\n",
    "    \"gan\",\n",
    "    \"wu\",\n",
    "    \"hakka\",\n",
    "    \"hawaii creole english\",\n",
    "    \"turkmen\",\n",
    "    \"garifuna\",\n",
    "    \"kru\",\n",
    "    \"irish\",\n",
    "    \"liberian pidgin english\",\n",
    "    \"papiamentu\",\n",
    "    \"ife\",\n",
    "    \"hiligaynon\",\n",
    "    \"temne\",\n",
    "    \"cameroon creole english\",\n",
    "    \"shan\",\n",
    "    \"ashanti\",\n",
    "    \"hmong\",\n",
    "    \"miskito\",\n",
    "    \"mizo\",\n",
    "    \"nicaragua creole english\",\n",
    "    \"tajiki\",\n",
    "    \"naxi\",\n",
    "    \"luba-kasai\",\n",
    "    \"tigre\",\n",
    "    \"wali\",\n",
    "    \"american sign language\",\n",
    "    \"home sign\",\n",
    "    \"ndebele\",\n",
    "    \"kamba\",\n",
    "    \"ossetic\",\n",
    "    \"voro\",\n",
    "    \"masbatenyo\",\n",
    "    \"min nan\",\n",
    "    \"tumbuka\",\n",
    "]\n",
    "\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Yamnet as feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model = tf.saved_model.load(os.getcwd() + '/yamnet_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2401 training set and 601 validation set.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.getcwd() + \"/data/audio.csv\", on_bad_lines = 'skip' , delimiter= ';')\n",
    "# dataframe = df[(df[\"native_langs\"] == \"amharic\") | (df[\"native_langs\"] == \"indonesian\")]\n",
    "# print(len(df['native_langs'].unique()))\n",
    "# for lang in df['native_langs'].unique():\n",
    "#     print(f'\"{lang}\",')\n",
    "# print(dataframe.shape)\n",
    "# dataframe.head()\n",
    "\n",
    "\n",
    "split = int(len(df) * 0.8)\n",
    "train_df = df[:split]\n",
    "valid_df = df[split:]\n",
    "print(f\"There are {len(train_df)} training set and {len(valid_df)} validation set.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 47, in None  *\n        lambda x, y: filepath_to_embeddings(x, y)\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 21, in filepath_to_embeddings  *\n        audio_wav = load_16k_audio_wav(filename)\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 5, in load_16k_audio_wav  *\n        file_content = tfio.audio.AudioIOTensor(filename)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py\", line 663, in __init__  **\n        assert dtype is not None, \"dtype must be provided in graph mode\"\n\n    AssertionError: dtype must be provided in graph mode\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 54\u001b[0m\n\u001b[1;32m     46\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m     47\u001b[0m         \u001b[39mlambda\u001b[39;00m x, y: filepath_to_embeddings(x, y),\n\u001b[1;32m     48\u001b[0m         num_parallel_calls\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE,\n\u001b[1;32m     49\u001b[0m     )\u001b[39m.\u001b[39munbatch()\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mbatch(batch_size)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[0;32m---> 54\u001b[0m train_ds \u001b[39m=\u001b[39m dataframe_to_dataset(train_df)\n\u001b[1;32m     55\u001b[0m valid_ds \u001b[39m=\u001b[39m dataframe_to_dataset(valid_df)\n",
      "Cell \u001b[0;32mIn[46], line 46\u001b[0m, in \u001b[0;36mdataframe_to_dataset\u001b[0;34m(dataframe, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataframe_to_dataset\u001b[39m(dataframe, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m     42\u001b[0m     dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(\n\u001b[1;32m     43\u001b[0m         (dataframe[\u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m], dataframe[\u001b[39m\"\u001b[39m\u001b[39mnative_langs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     44\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m     47\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x, y: filepath_to_embeddings(x, y),\n\u001b[1;32m     48\u001b[0m         num_parallel_calls\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mAUTOTUNE,\n\u001b[1;32m     49\u001b[0m     )\u001b[39m.\u001b[39munbatch()\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mbatch(batch_size)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2296\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2294\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39m, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m   2295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2296\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2297\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2298\u001b[0m       map_func,\n\u001b[1;32m   2299\u001b[0m       num_parallel_calls,\n\u001b[1;32m   2300\u001b[0m       deterministic,\n\u001b[1;32m   2301\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2302\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5540\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m   5539\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m-> 5540\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5541\u001b[0m     map_func,\n\u001b[1;32m   5542\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5543\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5544\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5545\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5546\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:263\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    264\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:226\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    218\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m    227\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    228\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    229\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:192\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mvalidate_inputs_with_signature(args, kwargs)\n\u001b[1;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 192\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    193\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    194\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m    195\u001b[0m       concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:240\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    235\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    236\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    237\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    241\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    242\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:171\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    170\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 171\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    172\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/__autograph_generated_file0rjpfby9.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: ag__\u001b[39m.\u001b[39;49mwith_function_scope(\u001b[39mlambda\u001b[39;49;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(filepath_to_embeddings, (x, y), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39;49m\u001b[39mlscope\u001b[39;49m\u001b[39m'\u001b[39;49m, ag__\u001b[39m.\u001b[39;49mSTD)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/core/function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m FunctionScope(\u001b[39m'\u001b[39m\u001b[39mlambda_\u001b[39m\u001b[39m'\u001b[39m, scope_name, options) \u001b[39mas\u001b[39;00m scope:\n\u001b[0;32m--> 113\u001b[0m   \u001b[39mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[0;32m/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/__autograph_generated_file0rjpfby9.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: ag__\u001b[39m.\u001b[39mwith_function_scope(\u001b[39mlambda\u001b[39;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(filepath_to_embeddings, (x, y), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39m\u001b[39mlscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/__autograph_generated_filesz7x9ip9.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__filepath_to_embeddings\u001b[0;34m(filename, label)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m audio_wav \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(load_16k_audio_wav), (ag__\u001b[39m.\u001b[39;49mld(filename),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     11\u001b[0m (scores, embeddings, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(yamnet_model), (ag__\u001b[39m.\u001b[39mld(audio_wav),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m embeddings_num \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(embeddings),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/__autograph_generated_filewob6yzkq.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_16k_audio_wav\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m file_content \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tfio)\u001b[39m.\u001b[39;49maudio\u001b[39m.\u001b[39;49mAudioIOTensor, (ag__\u001b[39m.\u001b[39;49mld(filename),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     11\u001b[0m audio_decoded \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tfio)\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mdecode_mp3, (ag__\u001b[39m.\u001b[39mld(file_content),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m audio_decoded \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39msqueeze, (ag__\u001b[39m.\u001b[39mld(audio_decoded),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), fscope)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py:663\u001b[0m, in \u001b[0;36mAudioIOTensor.__init__\u001b[0;34m(self, filename, dtype)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mAudioIOTensor\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 663\u001b[0m         \u001b[39massert\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mdtype must be provided in graph mode\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m     resource \u001b[39m=\u001b[39m core_ops\u001b[39m.\u001b[39mio_audio_readable_init(filename)\n\u001b[1;32m    665\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 47, in None  *\n        lambda x, y: filepath_to_embeddings(x, y)\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 21, in filepath_to_embeddings  *\n        audio_wav = load_16k_audio_wav(filename)\n    File \"/var/folders/3p/fc9cp69s1lsfgnzqtqtddvz00000gn/T/ipykernel_47199/3737147357.py\", line 5, in load_16k_audio_wav  *\n        file_content = tfio.audio.AudioIOTensor(filename)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/audio_ops.py\", line 663, in __init__  **\n        assert dtype is not None, \"dtype must be provided in graph mode\"\n\n    AssertionError: dtype must be provided in graph mode\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def load_16k_audio_wav(filename):\n",
    "    # Read file content\n",
    "    # audio = tfio.audio.AudioIOTensor(AUDIOPATH + '/indonesian1.mp3')\n",
    "    file_content = tfio.audio.AudioIOTensor(filename)\n",
    "\n",
    "    # Decode audio\n",
    "    audio_decoded = tfio.audio.decode_mp3(file_content)\n",
    "    audio_decoded = tf.squeeze(audio_decoded, axis=-1)\n",
    "    sample_rate = tf.cast(file_content.rate, dtype=tf.int64)\n",
    "\n",
    "    # Resample to 16k\n",
    "    audio_wav = tfio.audio.resample(audio_decoded, rate_in=sample_rate, rate_out=16000)\n",
    "\n",
    "    return audio_wav\n",
    "\n",
    "\n",
    "\n",
    "def filepath_to_embeddings(filename, label):\n",
    "    # Load 16k audio wave\n",
    "    audio_wav = load_16k_audio_wav(filename)\n",
    "\n",
    "    # Get audio embeddings & scores.\n",
    "    # The embeddings are the audio features extracted using transfer learning\n",
    "    # while scores will be used to identify time slots that are not speech\n",
    "    # which will then be gathered into a specific new category 'other'\n",
    "    scores, embeddings, _ = yamnet_model(audio_wav)\n",
    "\n",
    "    # Number of embeddings in order to know how many times to repeat the label\n",
    "    embeddings_num = tf.shape(embeddings)[0]\n",
    "    labels = tf.repeat(label, embeddings_num)\n",
    "\n",
    "    # Change labels for time-slots that are not speech into a new category 'other'\n",
    "    labels = tf.where(tf.argmax(scores, axis=1) == 0, label, len(class_names) - 1)\n",
    "\n",
    "    # Using one-hot in order to use AUC\n",
    "    return (embeddings, tf.one_hot(labels, len(class_names)))\n",
    "\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe, batch_size=64):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"file_name\"], dataframe[\"native_langs\"])\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: filepath_to_embeddings(x, y),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    ).unbatch()\n",
    "\n",
    "    return dataset.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_df)\n",
    "valid_ds = dataframe_to_dataset(valid_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "def build_and_compile_model():\n",
    "    inputs = keras.layers.Input(shape=(1024), name=\"embedding\")\n",
    "\n",
    "    x = keras.layers.Dense(256, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = keras.layers.Dropout(0.15, name=\"dropout_1\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(384, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    x = keras.layers.Dropout(0.2, name=\"dropout_2\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(192, activation=\"relu\", name=\"dense_3\")(x)\n",
    "    x = keras.layers.Dropout(0.25, name=\"dropout_3\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(384, activation=\"relu\", name=\"dense_4\")(x)\n",
    "    x = keras.layers.Dropout(0.2, name=\"dropout_4\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"ouput\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"accent_recognition\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1.9644e-5),\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_and_compile_model()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = tf.zeros(shape=(len(class_names),), dtype=tf.int32)\n",
    "\n",
    "for x, y in iter(train_ds):\n",
    "    class_counts = class_counts + tf.math.bincount(\n",
    "        tf.cast(tf.math.argmax(y, axis=1), tf.int32), minlength=len(class_names)\n",
    "    )\n",
    "\n",
    "class_weight = {\n",
    "    i: tf.math.reduce_sum(class_counts).numpy() / class_counts[i].numpy()\n",
    "    for i in range(len(class_counts))\n",
    "}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_NAME + \".h5\", monitor=\"val_auc\", save_best_only=True\n",
    ")\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "    os.path.join(os.curdir, \"logs\", model.name)\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Plot the training and validation AUC and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "axs[0].plot(range(EPOCHS), history.history[\"accuracy\"], label=\"Training\")\n",
    "axs[0].plot(range(EPOCHS), history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_title(\"Training & Validation Accuracy\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].plot(range(EPOCHS), history.history[\"auc\"], label=\"Training\")\n",
    "axs[1].plot(range(EPOCHS), history.history[\"val_auc\"], label=\"Validation\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_title(\"Training & Validation AUC\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, train_auc = model.evaluate(train_ds)\n",
    "valid_loss, valid_acc, valid_auc = model.evaluate(valid_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
